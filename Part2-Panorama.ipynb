{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def ensure_output_folder(folder):\n",
    "    \"\"\"Create the output folder if it doesn't already exist.\"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def load_images(folder_path):\n",
    "    \"\"\"Load all images (jpg, png, etc.) from a folder.\"\"\"\n",
    "    image_paths = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif', '.tiff')):\n",
    "            image_paths.append(os.path.join(folder_path, filename))\n",
    "    image_paths.sort()  # Ensure a consistent order\n",
    "    \n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "        else:\n",
    "            print(f\"Warning: Could not load {path}\")\n",
    "    return images\n",
    "\n",
    "def detect_features(images, method=\"ORB\"):\n",
    "    \"\"\"\n",
    "    Detect keypoints and compute descriptors for each image using either ORB or SIFT.\n",
    "    \n",
    "    Args:\n",
    "        images (list): List of images.\n",
    "        method (str): 'ORB' or 'SIFT'\n",
    "        \n",
    "    Returns:\n",
    "        keypoints_list: List of lists of keypoints for each image.\n",
    "        descriptors_list: List of descriptor arrays for each image.\n",
    "    \"\"\"\n",
    "    method = method.upper()\n",
    "    if method == \"ORB\":\n",
    "        detector = cv2.ORB_create(nfeatures=2000)\n",
    "    elif method == \"SIFT\":\n",
    "        detector = cv2.SIFT_create()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Use 'ORB' or 'SIFT'.\")\n",
    "    \n",
    "    keypoints_list = []\n",
    "    descriptors_list = []\n",
    "    for img in images:\n",
    "        kp, des = detector.detectAndCompute(img, None)\n",
    "        keypoints_list.append(kp)\n",
    "        descriptors_list.append(des)\n",
    "    return keypoints_list, descriptors_list\n",
    "\n",
    "def draw_and_save_keypoints(images, keypoints_list, method, output_folder):\n",
    "    \"\"\"\n",
    "    Draw and save images with detected keypoints for visual verification.\n",
    "    \n",
    "    Args:\n",
    "        images (list of np.ndarray): Original images.\n",
    "        keypoints_list (list of lists): Corresponding keypoints for each image.\n",
    "        method (str): 'SIFT' or 'ORB' (for labeling).\n",
    "        output_folder (str): Where to save the keypoint-annotated images.\n",
    "    \"\"\"\n",
    "    method = method.upper()\n",
    "    for idx, (img, kps) in enumerate(zip(images, keypoints_list)):\n",
    "        out_img = cv2.drawKeypoints(img, kps, None, flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "        filename = os.path.join(output_folder, f\"keypoints_{method}_{idx}.jpg\")\n",
    "        cv2.imwrite(filename, out_img)\n",
    "        print(f\"Saved keypoints for {method} (image {idx}): {filename}\")\n",
    "\n",
    "def match_keypoints(descriptors_list, method=\"ORB\", ratio_thresh=0.75):\n",
    "    \"\"\"\n",
    "    Match keypoints between consecutive images.\n",
    "    - If method='ORB', use Hamming distance.\n",
    "    - If method='SIFT', use L2 (NORM_L2).\n",
    "    \n",
    "    Returns:\n",
    "        matches_list: List of 'good' matches between consecutive images\n",
    "                      (i.e., matches_list[i] is for images i and i+1)\n",
    "    \"\"\"\n",
    "    method = method.upper()\n",
    "    if method == \"ORB\":\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    else:  # SIFT\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2)\n",
    "    \n",
    "    matches_list = []\n",
    "    for i in range(len(descriptors_list) - 1):\n",
    "        des1 = descriptors_list[i]\n",
    "        des2 = descriptors_list[i+1]\n",
    "        if des1 is None or des2 is None:\n",
    "            print(f\"Warning: Descriptors missing for image {i} or {i+1}\")\n",
    "            matches_list.append(None)\n",
    "            continue\n",
    "        \n",
    "        raw_matches = bf.knnMatch(des1, des2, k=2)\n",
    "        good = []\n",
    "        for m, n in raw_matches:\n",
    "            if m.distance < ratio_thresh * n.distance:\n",
    "                good.append(m)\n",
    "        matches_list.append(good)\n",
    "    return matches_list\n",
    "\n",
    "def compute_homographies(matches_list, keypoints_list):\n",
    "    \"\"\"\n",
    "    Compute homography for each pair of consecutive images using the matches.\n",
    "    \n",
    "    Returns:\n",
    "        homographies: List of homography matrices for pairs (i, i+1)\n",
    "                      (homographies[i] warps image i+1 to image i's coordinate space)\n",
    "    \"\"\"\n",
    "    homographies = []\n",
    "    for i, matches in enumerate(matches_list):\n",
    "        if matches is None or len(matches) < 4:\n",
    "            print(f\"Not enough matches to compute homography between images {i} and {i+1}.\")\n",
    "            homographies.append(None)\n",
    "            continue\n",
    "        \n",
    "        kp1 = keypoints_list[i]\n",
    "        kp2 = keypoints_list[i+1]\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
    "        homographies.append(H)\n",
    "    return homographies\n",
    "\n",
    "def crop_black_areas(image):\n",
    "    \"\"\"\n",
    "    Crop away black (empty) regions from a stitched panorama.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Threshold to find non-black pixels\n",
    "    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "    if coords is not None:\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        return image[y:y+h, x:x+w]\n",
    "    return image\n",
    "\n",
    "def stitch_images_basic(images, method=\"ORB\", ratio_thresh=0.75):\n",
    "    \"\"\"\n",
    "    Stitch images using keypoint matching (ORB or SIFT) and cumulative homographies,\n",
    "    without any blending. Crop black areas at each iteration to avoid large gaps.\n",
    "    \n",
    "    Returns:\n",
    "        panorama (numpy.ndarray): Final stitched and cropped panorama.\n",
    "    \"\"\"\n",
    "    keypoints_list, descriptors_list = detect_features(images, method=method)\n",
    "    matches_list = match_keypoints(descriptors_list, method=method, ratio_thresh=ratio_thresh)\n",
    "    homographies = compute_homographies(matches_list, keypoints_list)\n",
    "    \n",
    "    # Start panorama with the first image\n",
    "    panorama = images[0]\n",
    "    H_cumulative = np.eye(3)\n",
    "    \n",
    "    for i in range(1, len(images)):\n",
    "        H = homographies[i - 1]\n",
    "        if H is None:\n",
    "            print(f\"Skipping image {i}, homography is None.\")\n",
    "            continue\n",
    "        # Update cumulative homography to map image i -> base image 0's coords\n",
    "        H_cumulative = H_cumulative @ H\n",
    "        \n",
    "        h1, w1 = panorama.shape[:2]\n",
    "        h2, w2 = images[i].shape[:2]\n",
    "        \n",
    "        # Rough estimate for output size\n",
    "        out_w = w1 + w2\n",
    "        out_h = max(h1, h2)\n",
    "        \n",
    "        warped = cv2.warpPerspective(images[i], H_cumulative, (out_w, out_h))\n",
    "        # Place the existing panorama in the warped image\n",
    "        warped[0:h1, 0:w1] = panorama\n",
    "        \n",
    "        # Crop black regions before going to next iteration\n",
    "        panorama = crop_black_areas(warped)\n",
    "\n",
    "    return panorama\n",
    "\n",
    "def feather_blend(base, warped, blend_width=30):\n",
    "    \"\"\"\n",
    "    Feather blend the overlapping region between base and warped images.\n",
    "    Assumes base and warped have the same height and partially overlapping width.\n",
    "    \"\"\"\n",
    "    h_base, w_base = base.shape[:2]\n",
    "    h_warp, w_warp = warped.shape[:2]\n",
    "    out_w = max(w_base, w_warp)\n",
    "    out_h = max(h_base, h_warp)\n",
    "    \n",
    "    blended = np.zeros((out_h, out_w, 3), dtype=np.uint8)\n",
    "    blended[:h_base, :w_base] = base\n",
    "    \n",
    "    overlap_x_start = 0\n",
    "    overlap_x_end = min(w_base, w_warp)\n",
    "    \n",
    "    for x in range(overlap_x_start, overlap_x_end):\n",
    "        dist_to_base_edge = w_base - x\n",
    "        if x >= w_base:\n",
    "            blended[:h_warp, x] = warped[:h_warp, x]\n",
    "        elif x >= w_warp:\n",
    "            continue\n",
    "        else:\n",
    "            alpha = 1.0\n",
    "            if dist_to_base_edge < blend_width:\n",
    "                alpha = dist_to_base_edge / float(blend_width)\n",
    "            for y in range(0, min(h_base, h_warp)):\n",
    "                px_base = base[y, x]\n",
    "                px_warp = warped[y, x]\n",
    "                blended[y, x] = alpha * px_base + (1 - alpha) * px_warp\n",
    "    \n",
    "    # Copy remaining right portion if warped is wider\n",
    "    if w_warp > w_base:\n",
    "        blended[:h_warp, w_base:w_warp] = warped[:h_warp, w_base:w_warp]\n",
    "    \n",
    "    return blended\n",
    "\n",
    "def stitch_images_feathered(images, method=\"ORB\", ratio_thresh=0.75, blend_width=30):\n",
    "    \"\"\"\n",
    "    Stitch images using keypoint matching (ORB or SIFT) and cumulative homographies.\n",
    "    Apply feather blending, and crop black areas at each iteration.\n",
    "    \"\"\"\n",
    "    keypoints_list, descriptors_list = detect_features(images, method=method)\n",
    "    matches_list = match_keypoints(descriptors_list, method=method, ratio_thresh=ratio_thresh)\n",
    "    homographies = compute_homographies(matches_list, keypoints_list)\n",
    "    \n",
    "    panorama = images[0]\n",
    "    H_cumulative = np.eye(3)\n",
    "    \n",
    "    for i in range(1, len(images)):\n",
    "        H = homographies[i - 1]\n",
    "        if H is None:\n",
    "            print(f\"Skipping image {i}, homography is None.\")\n",
    "            continue\n",
    "        H_cumulative = H_cumulative @ H\n",
    "        \n",
    "        h_pano, w_pano = panorama.shape[:2]\n",
    "        h2, w2 = images[i].shape[:2]\n",
    "        out_w = w_pano + w2\n",
    "        out_h = max(h_pano, h2)\n",
    "        \n",
    "        warped = cv2.warpPerspective(images[i], H_cumulative, (out_w, out_h))\n",
    "        \n",
    "        # Feather-blend the new warped image with the current panorama\n",
    "        blended = feather_blend(panorama, warped, blend_width=blend_width)\n",
    "        \n",
    "        # Crop black areas before going to next iteration\n",
    "        panorama = crop_black_areas(blended)\n",
    "    \n",
    "    return panorama\n",
    "\n",
    "def main():\n",
    "    # Configure folders\n",
    "    input_folder = \"Inputs/Part-2\"\n",
    "    output_folder = os.path.join(\"Outputs\", \"Part2\")\n",
    "    ensure_output_folder(output_folder)\n",
    "    \n",
    "    # Load input images\n",
    "    images = load_images(input_folder)\n",
    "    if len(images) < 2:\n",
    "        print(\"Not enough images to stitch.\")\n",
    "        return\n",
    "    \n",
    "    # --- SIFT Keypoints ---\n",
    "    keypoints_sift, descriptors_sift = detect_features(images, method=\"SIFT\")\n",
    "    draw_and_save_keypoints(images, keypoints_sift, \"SIFT\", output_folder)\n",
    "\n",
    "    # Stitch with SIFT (no blending), cropping black regions at each step\n",
    "    print(\"\\nStitching with SIFT (no blending, iterative crop)...\")\n",
    "    panorama_sift_basic = stitch_images_basic(images, method=\"SIFT\", ratio_thresh=0.75)\n",
    "    sift_basic_path = os.path.join(output_folder, \"final_panorama_sift_itercrop.jpg\")\n",
    "    cv2.imwrite(sift_basic_path, panorama_sift_basic)\n",
    "    print(f\"Saved: {sift_basic_path}\")\n",
    "    \n",
    "    # Stitch with SIFT + Feather Blending, cropping black regions at each step\n",
    "    print(\"\\nStitching with SIFT + Feather Blending (iterative crop)...\")\n",
    "    panorama_sift_feather = stitch_images_feathered(images, method=\"SIFT\", ratio_thresh=0.75, blend_width=50)\n",
    "    sift_feather_path = os.path.join(output_folder, \"final_panorama_sift_feather_itercrop.jpg\")\n",
    "    cv2.imwrite(sift_feather_path, panorama_sift_feather)\n",
    "    print(f\"Saved: {sift_feather_path}\")\n",
    "\n",
    "    # --- ORB Keypoints ---\n",
    "    keypoints_orb, descriptors_orb = detect_features(images, method=\"ORB\")\n",
    "    draw_and_save_keypoints(images, keypoints_orb, \"ORB\", output_folder)\n",
    "\n",
    "    # Stitch with ORB (no blending), cropping black regions at each step\n",
    "    print(\"\\nStitching with ORB (no blending, iterative crop)...\")\n",
    "    panorama_orb_basic = stitch_images_basic(images, method=\"ORB\", ratio_thresh=0.75)\n",
    "    orb_basic_path = os.path.join(output_folder, \"final_panorama_orb_itercrop.jpg\")\n",
    "    cv2.imwrite(orb_basic_path, panorama_orb_basic)\n",
    "    print(f\"Saved: {orb_basic_path}\")\n",
    "\n",
    "    # Stitch with ORB + Feather Blending\n",
    "    print(\"\\nStitching with ORB + Feather Blending (iterative crop)...\")\n",
    "    panorama_orb_feather = stitch_images_feathered(images, method=\"ORB\", ratio_thresh=0.75, blend_width=50)\n",
    "    orb_feather_path = os.path.join(output_folder, \"final_panorama_orb_feather_itercrop.jpg\")\n",
    "    cv2.imwrite(orb_feather_path, panorama_orb_feather)\n",
    "    print(f\"Saved: {orb_feather_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
